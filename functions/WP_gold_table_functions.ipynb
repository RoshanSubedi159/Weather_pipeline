{"cells":[{"cell_type":"markdown","source":["### Function to create and load data into fact table for hourly weather"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"caaec15e-9172-4394-b30d-cf09f8b24e52","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["@logger\ndef load_hourly_weather_data(clean_weather_df):\n    \n    # importing required libraries\n    from pyspark.sql.functions import col, hour\n    from datetime import datetime\n    \n    clean_weather_df = clean_weather_df.withColumn(\"Date\", col(\"created_on\").cast('Date')).withColumn(\"timeID\", hour('created_on'))\n    \n    try:\n        timeID, date = clean_weather_df.select('timeID', 'Date').first()\n        dateID = str(date).replace('-', '')\n        query = f\"delete from fact_hourly_weather where timeID='{timeID}' and date_key='{dateID}';\"\n        spark.sql(query)\n    except:\n        pass\n    \n    date_df = spark.table(\"dim_date_table\")\n    fact_weather_df = clean_weather_df.join(date_df, date_df.full_date == clean_weather_df.Date).select(\n                            clean_weather_df.timeID,\n                            date_df.date_key,\n                            clean_weather_df.city_id,\n                            clean_weather_df.temperature,\n                            clean_weather_df.minimum_temperature,\n                            clean_weather_df.maximum_temperature,\n                            clean_weather_df.pressure,\n                            clean_weather_df.humidity,\n                            clean_weather_df.visibility,\n                            clean_weather_df.wind_speed,\n                            clean_weather_df.wind_degree,\n                            clean_weather_df.wind_gust,\n                            clean_weather_df.clouds_all\n    )\n    \n    start = datetime.fromtimestamp(clean_weather_df.selectExpr(\"min(dt)\").first()[0])\n    end = datetime.fromtimestamp(clean_weather_df.selectExpr(\"max(dt)\").first()[0])\n    \n    return fact_weather_df, start, end\n    "],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9619411e-4105-4f06-a77f-c646a9ed83f1","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Function to create and load data into fact table for daily weather"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9be8bf77-4b11-433c-9f91-0cd0c017d892","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["@logger\ndef load_daily_weather_data():\n    \n    from pyspark.sql.functions import col, mean, max, min\n    from datetime import datetime\n    \n    \n    hourly_weather_df = spark.sql(f\"SELECT\\\n                                      *\\\n                                  FROM\\\n                                      fact_hourly_weather\\\n                                  WHERE\\\n                                      date_key =\\\n                                      (\\\n                                         SELECT max(date_key) FROM fact_hourly_weather\\\n                                      );\\\n                                   \").drop('load_run_id', 'created_on', 'created_by', 'timeID')\n    try:\n        spark.sql(f\"delete from fact_daily_weather where date_key = (select max(date_key) from fact_hourly_weather);\")\n    except:\n        pass\n    \n    daily_weather_df = hourly_weather_df.groupby(\n                       col('city_id'), col('date_key')).agg(mean(\"temperature\").alias('temperature'), \n                             min('minimum_temperature').alias('minimum_temperature'), \n                             max('maximum_temperature').alias('maximum_temperature'), \n                             mean('pressure').cast('int').alias('pressure'), \n                             mean('humidity').cast('int').alias('humidity'), \n                             mean('visibility').cast('int').alias('visibility'),\n                             mean('wind_speed').cast('int').alias('wind_speed'),\n                             mean('wind_degree').cast('int').alias('wind_degree'), \n                             mean('wind_gust').alias('wind_gust'),\n                             mean('clouds_all').alias('clouds_all')\n                            )\n    start = datetime.fromtimestamp(hourly_weather_df.selectExpr(\"min(date_key)\").first()[0])\n    end = datetime.fromtimestamp(hourly_weather_df.selectExpr(\"max(date_key)\").first()[0])\n    \n    return daily_weather_df, start, end"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"3b962756-dee5-4163-9c4f-b8f7bfd2a6d3","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"WP_gold_table_functions","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
