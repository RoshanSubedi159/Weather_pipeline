{"cells":[{"cell_type":"markdown","source":["### Function to create and load data into fact table for hourly weather"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"caaec15e-9172-4394-b30d-cf09f8b24e52","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["@logger\ndef load_hourly_weather_data_with_forecast(clean_weather_df):\n    \n    # importing required libraries\n    from pyspark.sql.functions import col, hour, lit, mean, max, min\n    from datetime import datetime, timedelta\n    \n    clean_weather_df = clean_weather_df.withColumn(\"Date\", col(\"created_on\").cast('Date')).withColumn(\"timeID\", hour('created_on'))\n    \n    try:\n        timeID, date = clean_weather_df.select('timeID', 'Date').first()\n        dateID = str(date).replace('-', '')\n        query = f\"delete from fact_hourly_weather where timeID>='{timeID}' and date_key>='{dateID}';\"\n        spark.sql(query)\n    except:\n        pass\n    \n    date_df = spark.table(\"dim_date_table\")\n    fact_weather_df = clean_weather_df.join(date_df, date_df.full_date == clean_weather_df.Date).select(\n                            clean_weather_df.timeID,\n                            date_df.date_key,\n                            clean_weather_df.city_id,\n                            clean_weather_df.temperature,\n                            clean_weather_df.minimum_temperature,\n                            clean_weather_df.maximum_temperature,\n                            clean_weather_df.pressure,\n                            clean_weather_df.humidity,\n                            clean_weather_df.visibility,\n                            clean_weather_df.wind_speed,\n                            clean_weather_df.wind_degree,\n                            clean_weather_df.wind_gust,\n                            clean_weather_df.clouds_all\n    )\n    fact_weather_df = fact_weather_df.withColumn('Is_Forecast', lit(False))\n    \n    for i in range(1,5):\n        ext_timeID = (timeID - i) % 24\n        date_offset = int((timeID - i) // 24)\n        ext_date = date + timedelta(date_offset)\n        ext_dateID = str(date).replace('-', '')\n        try:\n            ext_weather_df = spark.sql(f\"SELECT * FROM fact_hourly_weather WHERE timeID = {ext_timeID} and date_key = {ext_dateID}\")\n            ext_weather_df = ext_weather_df.drop('load_run_id', 'created_on', 'created_by')\n            fact_weather_df = fact_weather_df.union(ext_weather_df)\n        except:\n            pass\n        \n    for i in range(1, 5):\n        ext_timeID = (timeID + i) % 24\n        date_offset = int((timeID + i) // 24)\n        ext_date = date + timedelta(date_offset)\n        ext_dateID = int(str(date).replace('-', ''))\n        \n        forecast_weather_df = fact_weather_df.groupby(\n                       col('city_id')).agg(mean(\"temperature\").alias('temperature'), \n                             min('minimum_temperature').alias('minimum_temperature'), \n                             max('maximum_temperature').alias('maximum_temperature'), \n                             mean('pressure').cast('int').alias('pressure'), \n                             mean('humidity').cast('int').alias('humidity'), \n                             mean('visibility').cast('int').alias('visibility'),\n                             mean('wind_speed').cast('int').alias('wind_speed'),\n                             mean('wind_degree').cast('int').alias('wind_degree'), \n                             mean('wind_gust').alias('wind_gust'),\n                             mean('clouds_all').alias('clouds_all')\n                            )\n        forecast_weather_df = forecast_weather_df.withColumn('timeID', lit(ext_timeID)).withColumn('date_key', lit(ext_dateID)).withColumn('Is_Forecast', lit(True))\n        forecast_weather_df = forecast_weather_df.select(\n                                                            \"timeID\",\n                                                            \"date_key\",\n                                                            \"city_id\",\n                                                            \"temperature\",\n                                                            \"minimum_temperature\",\n                                                            \"maximum_temperature\",\n                                                            \"pressure\",\n                                                            \"humidity\",\n                                                            \"visibility\",\n                                                            \"wind_speed\",\n                                                            \"wind_degree\",\n                                                            \"wind_gust\",\n                                                            \"clouds_all\",\n                                                            \"Is_Forecast\"\n                                                        )\n        fact_weather_df = fact_weather_df.union(forecast_weather_df)\n        drop_time_ID = (ext_timeID - 5) % 24\n        fact_weather_df = fact_weather_df.filter(col('timeID') != drop_time_ID)\n    \n    \n    start = datetime.fromtimestamp(clean_weather_df.selectExpr(\"min(dt)\").first()[0])\n    end = datetime.fromtimestamp(clean_weather_df.selectExpr(\"max(dt)\").first()[0])\n    \n    \n    return fact_weather_df, start, end\n    "],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"9619411e-4105-4f06-a77f-c646a9ed83f1","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-2772749447538956>:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;129m@logger\u001B[39m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_hourly_weather_data_with_forecast\u001B[39m(clean_weather_df):\n\u001B[1;32m      3\u001B[0m     \n\u001B[1;32m      4\u001B[0m     \u001B[38;5;66;03m# importing required libraries\u001B[39;00m\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpyspark\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msql\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m col, hour, lit, mean, \u001B[38;5;28mmax\u001B[39m, \u001B[38;5;28mmin\u001B[39m\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdatetime\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m datetime, timedelta\n\n\u001B[0;31mNameError\u001B[0m: name 'logger' is not defined","errorSummary":"<span class='ansi-red-fg'>NameError</span>: name 'logger' is not defined","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n","\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n","File \u001B[0;32m<command-2772749447538956>:1\u001B[0m\n","\u001B[0;32m----> 1\u001B[0m \u001B[38;5;129m@logger\u001B[39m\n","\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_hourly_weather_data_with_forecast\u001B[39m(clean_weather_df):\n","\u001B[1;32m      3\u001B[0m     \n","\u001B[1;32m      4\u001B[0m     \u001B[38;5;66;03m# importing required libraries\u001B[39;00m\n","\u001B[1;32m      5\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpyspark\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msql\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m col, hour, lit, mean, \u001B[38;5;28mmax\u001B[39m, \u001B[38;5;28mmin\u001B[39m\n","\u001B[1;32m      6\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdatetime\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m datetime, timedelta\n","\n","\u001B[0;31mNameError\u001B[0m: name 'logger' is not defined"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Function to create and load data into fact table for daily weather"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"9be8bf77-4b11-433c-9f91-0cd0c017d892","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["@logger\ndef load_daily_weather_data():\n    \n    from pyspark.sql.functions import col, mean, max, min, lit\n    from datetime import datetime\n    \n    \n#     hourly_weather_df = spark.sql(f\"SELECT\\\n#                                       *\\\n#                                   FROM\\\n#                                       (select * from fact_hourly_weather where Is_Forecast = False)\\\n#                                   WHERE\\\n#                                       date_key =\\\n#                                       (\\\n#                                          SELECT max(date_key) FROM fact_hourly_weather\\\n#                                       );\\\n#                                    \").drop('load_run_id', 'created_on', 'created_by', 'timeID', 'Is_Forecast')\n\n    hourly_weather_df = spark.table('fact_hourly_weather').filter(col('Is_Forecast') == False)\n    max_date = hourly_weather_df.select(max(col(\"date_key\"))).first()[0]\n    hourly_weather_df = hourly_weather_df.filter(col('date_key') == max_date).drop('load_run_id', 'created_on', 'created_by', 'timeID', 'Is_Forecast')\n    try:\n        spark.sql(f\"delete from fact_daily_weather where date_key = (select max(date_key) from fact_daily_weather);\")\n    except:\n        pass\n    \n    daily_weather_df = hourly_weather_df.groupby(\n                       col('city_id'), col('date_key')).agg(mean(\"temperature\").alias('temperature'), \n                             min('minimum_temperature').alias('minimum_temperature'), \n                             max('maximum_temperature').alias('maximum_temperature'), \n                             mean('pressure').cast('int').alias('pressure'), \n                             mean('humidity').cast('int').alias('humidity'), \n                             mean('visibility').cast('int').alias('visibility'),\n                             mean('wind_speed').cast('int').alias('wind_speed'),\n                             mean('wind_degree').cast('int').alias('wind_degree'), \n                             mean('wind_gust').cast('float').alias('wind_gust'),\n                             mean('clouds_all').alias('clouds_all')\n                            )\n    start = datetime.fromtimestamp(hourly_weather_df.selectExpr(\"min(date_key)\").first()[0])\n    end = datetime.fromtimestamp(hourly_weather_df.selectExpr(\"max(date_key)\").first()[0])\n    \n    return daily_weather_df, start, end"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"3b962756-dee5-4163-9c4f-b8f7bfd2a6d3","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"WP_gold_table_forecast","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4,"mostRecentlyExecutedCommandWithImplicitDF":{"commandId":1072707700271081,"dataframes":["_sqldf"]}},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
